{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "282d1115",
   "metadata": {},
   "source": [
    "# Analogy function\n",
    "\n",
    "\n",
    "Let us implement our own function to perform the analogy task. We will use the same distance metric as in  Mikolov, Tomas, et al. \"Efficient Estimation of Word Representations in Vector Space\" Advances in neural information processing systems. 2013. With this function, we want to be able to answer whether an analogy like: \"a king is to a queen as a man is to a woman\" (e_king - e_queen + e_man is e_woman) is true. In a perfect scenario, we would like that this analogy (e_king - e_queen + e_man) results in the embedding of the word \"man\". However, it does not always result in exactly the same word embedding. In this context, we will call \"man\" the true or the actual word. We want to find the word W in the vocabulary, where the embedding of W i.e e_W is the closest to the predicted embedding (i.e., the result of the formula). Then, we can check if W is the same word as the true word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef4a37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.models import load_model\n",
    "from scipy.spatial.distance import cosine, cdist\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d25ad9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipgram Model\n",
    "skipgram = load_model('models/sgm.h5')\n",
    "\n",
    "# CBOW Model\n",
    "cbow = load_model('models/cbm.h5')\n",
    "\n",
    "# Fasttext model\n",
    "fasttext = Word2Vec.load('models/fasttext.model')\n",
    "\n",
    "# LSA\n",
    "df_svd = pd.read_csv(\"models/lsa.csv\")\n",
    "df_svd = df_svd.set_index(\"words\")\n",
    "vocab = list(df_svd.index)\n",
    "\n",
    "# Glove\n",
    "from gensim.models import KeyedVectors\n",
    "glove = KeyedVectors.load('models/glove-wiki-gigaword-300.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a55d1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bbc-text.csv')\n",
    "articles = list(df['text'])\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for i in articles[:200]:\n",
    "    sentences += i.split('.')\n",
    "\n",
    "# Remove sentences with fewer than 3 words\n",
    "corpus = [sentence for sentence in sentences if sentence.count(\" \") >= 12]\n",
    "\n",
    "# Remove punctuation in text and fit tokenizer on entire corpus\n",
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\\t\\n'+\"'\")\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "# Convert text to sequence of integer values\n",
    "corpus = tokenizer.texts_to_sequences(corpus)\n",
    "n_samples = sum(len(s) for s in corpus) # Total number of words in the corpus\n",
    "V = len(tokenizer.word_index) + 1 # Total number of unique words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c851e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_skipgram_embeddings():\n",
    "    word_vectors = {}\n",
    "    i=0\n",
    "    with open(\"models/vectors_skipgram_300.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            i+=1\n",
    "            if i == 1:\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array([float(x) for x in parts[1:]])\n",
    "            word_vectors[word] = vector\n",
    "    return word_vectors\n",
    "\n",
    "\n",
    "def get_cbow_embeddings():\n",
    "    word_vectors = {}\n",
    "    i=0\n",
    "    with open(\"models/vectors_cbow_300.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            i+=1\n",
    "            if i == 1:\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array([float(x) for x in parts[1:]])\n",
    "            word_vectors[word] = vector\n",
    "    return word_vectors\n",
    "\n",
    "\n",
    "def get_fasttext_embeddings():\n",
    "    fasttext_model = Word2Vec.load('models/fasttext.model')\n",
    "    word_vectors = fasttext_model.wv\n",
    "    return word_vectors\n",
    "\n",
    "def get_lsa_embeddings():\n",
    "    word_vectors = {}\n",
    "    i=0\n",
    "    with open(\"models/vectors_lsa_300.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            i+=1\n",
    "            if i == 1:\n",
    "                continue\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vector = np.array([float(x) for x in parts[1:]])\n",
    "            word_vectors[word] = vector\n",
    "    return word_vectors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcc9b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nearest(k, target_word, word_vectors, model):\n",
    "    if target_word not in word_vectors:\n",
    "        print(f\"'{input_word}' is not present in the vocabulary.\")\n",
    "        return -1\n",
    "\n",
    "    # for fasttext\n",
    "    if model == 'fasttext':\n",
    "        embedding_vector = word_vectors[target_word]\n",
    "        similar_words = fasttext_model.wv.similar_by_word(target_word)\n",
    "\n",
    "        print(f\"\\nThe {k} nearest words to '{target_word}' are: \")\n",
    "        nearest_words = [(word,e) for word, e in similar_words[:k]]\n",
    "        for i in (nearest_words):\n",
    "            print(i)\n",
    "        return nearest_words        \n",
    "        \n",
    "    # for skipgram and cbow\n",
    "    if model in ['skipgram', 'cbow', 'lsa']: \n",
    "        # Calculate cosine similarities with all words in the vocabulary\n",
    "        similarities = {}\n",
    "        target_vector = word_vectors[target_word]\n",
    "        for word, vector in word_vectors.items():\n",
    "            if word != target_word:\n",
    "                cosine_sim = cosine_similarity([target_vector], [vector])\n",
    "                similarities[word] = cosine_sim[0][0]\n",
    "\n",
    "        # Sort the words by their cosine similarity scores in descending order\n",
    "        sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Select the top-k words as the k-nearest words\n",
    "        nearest_words = [(word, round(e,4)) for word, e in sorted_similarities[:k]]\n",
    "\n",
    "        # Print the k-nearest words\n",
    "        print(f\"\\nThe {k} nearest words to '{target_word}' are: \")\n",
    "        for i in (nearest_words):\n",
    "            print(i)\n",
    "        return nearest_words\n",
    "\n",
    "    \n",
    "def get_k_nearest_using_embedding(k, embed_prediction, word_vectors, model, fw):   \n",
    "    \n",
    "    if model == 'fasttext':\n",
    "        \n",
    "        vectors = fw.wv.vectors\n",
    "        words = fw.wv.index_to_key\n",
    "\n",
    "        # Calculate cosine similarity between the target vector and all other vectors\n",
    "        similarity_scores = [np.dot(embed_prediction, vectors[i]) / (np.linalg.norm(embed_prediction) * np.linalg.norm(vectors[i])) for i in range(len(vectors))]\n",
    "\n",
    "        # Find the indices of the k most similar words\n",
    "        top_k_indices = np.argsort(similarity_scores)[-k:][::-1]\n",
    "\n",
    "        # Get the corresponding words and their similarity scores\n",
    "        nearest_words = [(words[i], round(similarity_scores[i], 4)) for i in top_k_indices]\n",
    "\n",
    "        return nearest_words\n",
    "\n",
    "        \n",
    "    else: \n",
    "        embedding_matrix = [word_vectors[i] for i in word_vectors]\n",
    "        \n",
    "        similarity_scores = cosine_similarity([embed_prediction], embedding_matrix)[0]\n",
    "\n",
    "        top_k_indices = np.argsort(similarity_scores)[-k:][::-1]\n",
    "        nearest_words = [(word,similarity_scores[tokenizer.word_index[word]]) for word in tokenizer.word_index if tokenizer.word_index[word] in top_k_indices]\n",
    "\n",
    "        return nearest_words\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6826657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model_name):\n",
    "    \n",
    "    if model_name == 'fasttext':\n",
    "        return get_fasttext_embeddings()\n",
    "    \n",
    "    if model_name == 'skipgram':\n",
    "        return get_skipgram_embeddings()\n",
    "    \n",
    "    if model_name == 'cbow':\n",
    "        return get_cbow_embeddings()\n",
    "    \n",
    "    if model_name == 'lsa':\n",
    "        return get_lsa_embeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7abb857",
   "metadata": {},
   "source": [
    "The method we have created above is relatively simple. Let us consider the major steps of the method. The method boils down to: \n",
    "\n",
    "1) concatenating all models such that it is easier to iterate over all models\n",
    "\n",
    "2) get the embeddings of each model such that we can easily iterate over them\n",
    "\n",
    "3) store the model names in a list such that we can easily iterate over them\n",
    "4) create a list of tuples of size four where each word in the tuple represents a word in the analogy\n",
    "5) iterate over each tuple in the analogies we want to look at\n",
    "6) compute the embedding of each word in the tuple\n",
    "7) fill in the analogy function using the first three words\n",
    "8) make a prediction based on the outcome of the analogy function and return the nr nearest words using the cosine distance\n",
    "9) compare if the actual word (given as input parameter) is equal to the predicted word. \n",
    "\n",
    "This is the main idea behind the method. We have also made it easier to return the top 10 of nearest words and print the top 10 nearest words for each prediction together with the cosine distances to give us more of an idea as to what the model is predicting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8fe0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_analogy(analogy, model_names):\n",
    "    \n",
    "    # Retrieve the words from the analogy we need to compute\n",
    "    word_a, word_b, word_c, word_true = analogy    \n",
    "        \n",
    "    # Formulate the analogy task\n",
    "    analogy_task = f\"{word_a} is to {word_b} as {word_c} is to ?\"\n",
    "\n",
    "    print(f\"Analogy Task: {analogy_task}\")\n",
    "    print(\"---------------------------------------------------\")\n",
    "    \n",
    "    g_word = glove.most_similar(positive=[word_a, word_c], negative=[ word_b], topn=1)\n",
    "    print(f\"Glove prediction for Analogy is : {g_word}\\n\\n\")\n",
    "    \n",
    "    \n",
    "    if word_true not in vocab or word_a not in vocab or word_b not in vocab or word_c not in vocab:\n",
    "        model_names.remove('lsa')\n",
    "        print(\"Some input word or words not in vocab of LSA\\n\\n\")\n",
    "    \n",
    "    if word_true not in tokenizer.word_index or word_a not in tokenizer.word_index or word_b not in tokenizer.word_index or word_c not in tokenizer.word_index:\n",
    "        model_names.remove('skipgram')\n",
    "        model_names.remove('cbow')\n",
    "        print(\"Some input word or words not in vocab of skipgram and cbow\\n\\n\")\n",
    "\n",
    "\n",
    "    for model in model_names:\n",
    "        embeddings = get_embeddings(model)\n",
    "        embed_a, embed_b, embed_c, embed_true = embeddings[word_a],embeddings[word_b],embeddings[word_c],embeddings[word_true]\n",
    "        embed_prediction = embed_b - embed_a + embed_c\n",
    "        sim1 = round(cosine(embed_true, embed_prediction), 4)\n",
    "        nearest_words = get_k_nearest_using_embedding(10, embed_prediction, embeddings, model, fasttext)  \n",
    "        sorted_similarities = sorted(nearest_words, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        word_prediction, sim2 = sorted_similarities[0]\n",
    "\n",
    "    \n",
    "        # Print whether or not the true word was in the top nr \n",
    "        partially_correct = word_true in [word[0] for word in nearest_words]\n",
    "        \n",
    "        print(f\"Embedding: {model}\")\n",
    "        # Print all top nr words with their distance\n",
    "        for word in nearest_words:\n",
    "            print(f\"{word[0]} => {round(word[1], 4)}\")\n",
    "        print(f\"Predicted: {word_prediction} ({round(sim2, 4)}) - True: {word_true} ({sim1})\")\n",
    "        print(f\"Correct? {word_prediction == word_true} - In the top {10}? {partially_correct}\")\n",
    "        print(\"---------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f572784f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analogy Task: he is to is as we is to ?\n",
      "---------------------------------------------------\n",
      "Glove prediction for Analogy is : [('did', 0.6850758194923401)]\n",
      "\n",
      "\n",
      "Some input word or words not in vocab of LSA\n",
      "\n",
      "\n",
      "Embedding: skipgram\n",
      "it => 0.6\n",
      "had => 0.5821\n",
      "grow => 0.289\n",
      "missing => 0.2676\n",
      "debts => 0.2881\n",
      "examining => 0.2983\n",
      "clarion => 0.2867\n",
      "yankee => 0.3059\n",
      "surround => 0.2824\n",
      "encountered => 0.2754\n",
      "Predicted: it (0.6) - True: are (0.8858)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Embedding: cbow\n",
      "it => 0.6132\n",
      "had => 0.4804\n",
      "competition => 0.2715\n",
      "gave => 0.2701\n",
      "fogg => 0.2793\n",
      "alive => 0.2659\n",
      "examining => 0.3121\n",
      "prioritised => 0.2855\n",
      "fishermen => 0.3056\n",
      "osborne => 0.2678\n",
      "Predicted: it (0.6132) - True: are (0.918)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Embedding: fasttext\n",
      "is => 0.7296000123023987\n",
      "we => 0.5976999998092651\n",
      "re => 0.5037999749183655\n",
      "why. => 0.3529999852180481\n",
      "are => 0.34950000047683716\n",
      "will => 0.3407999873161316\n",
      "tseat. => 0.3386000096797943\n",
      "am => 0.3255999982357025\n",
      "i-fi. => 0.3244999945163727\n",
      "basking => 0.31679999828338623\n",
      "Predicted: is (0.7296000123023987) - True: are (0.6505)\n",
      "Correct? False - In the top 10? True\n",
      "---------------------------------------------------\n",
      "\n",
      "Analogy Task: love is to hate as little is to ?\n",
      "---------------------------------------------------\n",
      "Glove prediction for Analogy is : [('good', 0.5581995844841003)]\n",
      "\n",
      "\n",
      "Some input word or words not in vocab of LSA\n",
      "\n",
      "\n",
      "Embedding: skipgram\n",
      "claims => 0.3849\n",
      "michael => 0.6886\n",
      "torture => 0.3714\n",
      "thumbs => 0.4791\n",
      "ewood => 0.3568\n",
      "ravenhill => 0.3742\n",
      "netted => 0.3538\n",
      "devoted => 0.3642\n",
      "costly => 0.4013\n",
      "allegiance => 0.4242\n",
      "Predicted: michael (0.6886) - True: large (1.0522)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Embedding: cbow\n",
      "michael => 0.6543\n",
      "surprise => 0.3826\n",
      "dream => 0.3806\n",
      "apart => 0.3396\n",
      "thumbs => 0.5055\n",
      "chiefs => 0.3576\n",
      "incident => 0.3394\n",
      "speeded => 0.3319\n",
      "avoiding => 0.3328\n",
      "allegiance => 0.3425\n",
      "Predicted: michael (0.6543) - True: large (1.0383)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Embedding: fasttext\n",
      "little => 0.6029000282287598\n",
      "hate => 0.6025000214576721\n",
      "ittle => 0.5450999736785889\n",
      "littl => 0.531499981880188\n",
      "(wha => 0.4596000015735626\n",
      "(litt => 0.44519999623298645\n",
      "ittl => 0.4422000050544739\n",
      "(littl => 0.43309998512268066\n",
      "atea => 0.4325999915599823\n",
      "cruffy => 0.430400013923645\n",
      "Predicted: little (0.6029000282287598) - True: large (0.8949)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Analogy Task: small is to smaller as large is to ?\n",
      "---------------------------------------------------\n",
      "Glove prediction for Analogy is : [('huge', 0.6098418831825256)]\n",
      "\n",
      "\n",
      "Embedding: skipgram\n",
      "foundation => 0.4974\n",
      "facilities => 0.6651\n",
      "fifth => 0.2678\n",
      "yuan => 0.2721\n",
      "outrage => 0.2747\n",
      "sejong => 0.282\n",
      "complied => 0.267\n",
      "accelerate => 0.2892\n",
      "tendencies => 0.2884\n",
      "spurt => 0.2782\n",
      "Predicted: facilities (0.6651) - True: larger (0.8697)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Embedding: cbow\n",
      "foundation => 0.3986\n",
      "facilities => 0.6874\n",
      "glasgow => 0.2639\n",
      "twelve => 0.2582\n",
      "conditions => 0.2774\n",
      "rochus => 0.2662\n",
      "scoring => 0.2692\n",
      "glass => 0.2749\n",
      "complied => 0.263\n",
      "ux50 => 0.2651\n",
      "Predicted: facilities (0.6874) - True: larger (0.8771)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Embedding: fasttext\n",
      "smaller => 0.6485000252723694\n",
      "large => 0.5501000285148621\n",
      "larg => 0.4133000075817108\n",
      "arge => 0.351500004529953\n",
      "ruptci => 0.3513000011444092\n",
      "uptcie => 0.35010001063346863\n",
      "embargo. => 0.34599998593330383\n",
      "ptcies => 0.34450000524520874\n",
      "rcutti => 0.34389999508857727\n",
      "backlogs => 0.33899998664855957\n",
      "Predicted: smaller (0.6485000252723694) - True: larger (0.6786)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Embedding: lsa\n",
      "parliament => 0.2065\n",
      "wife => 0.1733\n",
      "signs => 0.6278\n",
      "bigger => 0.1852\n",
      "jamie => 0.546\n",
      "attachment => 0.17\n",
      "jon => 0.2041\n",
      "opened => 0.1978\n",
      "calm => 0.1923\n",
      "joseph => 0.1952\n",
      "Predicted: signs (0.6278) - True: larger (0.908)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Analogy Task: man is to woman as king is to ?\n",
      "---------------------------------------------------\n",
      "Glove prediction for Analogy is : [('brother', 0.5239033699035645)]\n",
      "\n",
      "\n",
      "Embedding: skipgram\n",
      "spokesman => 0.5743\n",
      "carpenter => 0.5077\n",
      "veto => 0.2568\n",
      "presumption => 0.2526\n",
      "fisher => 0.3145\n",
      "tarnation => 0.2591\n",
      "cooling => 0.314\n",
      "150th => 0.2542\n",
      "timed => 0.2769\n",
      "diagnosis => 0.2604\n",
      "Predicted: spokesman (0.5743) - True: queen (0.9203)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Embedding: cbow\n",
      "problems => 0.3028\n",
      "spokesman => 0.6764\n",
      "carpenter => 0.4784\n",
      "victims => 0.2952\n",
      "marriage => 0.3054\n",
      "postponed => 0.3311\n",
      "ongaro => 0.3006\n",
      "ballot => 0.3036\n",
      "witch => 0.3354\n",
      "disney => 0.2954\n",
      "Predicted: spokesman (0.6764) - True: queen (0.8246)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Embedding: fasttext\n",
      "king => 0.7035999894142151\n",
      "woman => 0.663100004196167\n",
      "woma => 0.5169000029563904\n",
      "viki => 0.4715999960899353\n",
      "ex-ki => 0.4715000092983246\n",
      "sk-ta => 0.47029998898506165\n",
      "isk-t => 0.46869999170303345\n",
      "rucki => 0.46709999442100525\n",
      "e-ban => 0.46540001034736633\n",
      "risk- => 0.46320000290870667\n",
      "Predicted: king (0.7035999894142151) - True: queen (0.8156)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Embedding: lsa\n",
      "seven => 0.167\n",
      "recently => 0.1616\n",
      "9 => 0.1619\n",
      "faces => 0.4838\n",
      "confident => 0.1602\n",
      "myers => 0.1649\n",
      "knee => 0.6026\n",
      "gathered => 0.163\n",
      "fewer => 0.1671\n",
      "moscow => 0.1625\n",
      "Predicted: knee (0.6026) - True: queen (0.8831)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "Analogy Task: mouse is to mice as cat is to ?\n",
      "---------------------------------------------------\n",
      "Glove prediction for Analogy is : [('dog', 0.56100994348526)]\n",
      "\n",
      "\n",
      "Some input word or words not in vocab of LSA\n",
      "\n",
      "\n",
      "Some input word or words not in vocab of skipgram and cbow\n",
      "\n",
      "\n",
      "Embedding: fasttext\n",
      "cat => 0.7332000136375427\n",
      "cate => 0.40149998664855957\n",
      "category => 0.3767000138759613\n",
      "catherina => 0.37439998984336853\n",
      "catalan => 0.374099999666214\n",
      "mice => 0.3700000047683716\n",
      "r-five => 0.36239999532699585\n",
      "dupl => 0.35929998755455017\n",
      "opyc => 0.3562999963760376\n",
      "catholicism => 0.3560999929904938\n",
      "Predicted: cat (0.7332000136375427) - True: cats (0.7572)\n",
      "Correct? False - In the top 10? False\n",
      "---------------------------------------------------\n",
      "\n",
      "CPU times: user 27.4 s, sys: 5.28 s, total: 32.6 s\n",
      "Wall time: 9.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "analogies = [('he', 'is', 'we', 'are'), ('love', 'hate', 'little', 'large'), ('small', 'smaller', 'large', 'larger'), ('man', 'woman', 'king', 'queen'), ('mouse', 'mice', 'cat', 'cats')]\n",
    "for analogy in analogies:\n",
    "    print_analogy(analogy, ['skipgram', 'cbow', 'fasttext', 'lsa'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f6651c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Conclusion\n",
    "In terms of performance, we observe that none of the six models managed to correctly predict any of the analogies; all predictions were incorrect. The major reason for this concerns the size of our corpus. Our corpus, namely alice.txt, has only 26,283 words before processing the file, which is a lot less than the millions of words that are mentioned by Mikolov, Tomas, et al. \"Efficient Estimation of Word Representations in Vector Space\" Advances in neural information processing systems. 2013.\n",
    "\n",
    "This suggests that our models are simply not able to learn much from our corpus since there is not that much to learn from.\n",
    "\n",
    "**Note** : However, for analogy \"small is to smaller as large is to ? (larger)\" Fasttext predicted \"smaller\" and for \"man is to woman as king is to ? (queen)\" Fasttext predicted king.\n",
    "Also, \"small is to smaller as large is to ? (larger)\" LSA predicted one of the simlar word as \"bigger\" which is somewhat related to \"larger\".\n",
    "\n",
    "Given the poor performance of both all 4 models on the analogies (on our corpus), it is tough to say which model performs better. To be able to draw sound conclusions on which type of model is more suitable for predicting analogies, we believe that we would require a larger corpus. If we were to draw a conclusion from the results we have right now, we would argue that Fasttext performs slightly better since it almost predicted the somewhat similar word, as mentioned above. Also as per \"Comparative study of LSA vs Word2vec embeddings\n",
    "in small corpora: a case study in dreams database\" by Edgar Altszyler commented that when the corpus size is reduced, Word2vec performance has a severe decrease, thus LSA becoming the more suitable tool comapred to Skipgram. Same is concluded from above analogy results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b637b8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b36302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef496ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3ef85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07fa791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
