{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Approach 1**: Using fastText function. ⚡\n",
        "\n"
      ],
      "metadata": {
        "id": "lSQ7mAzZsQ8H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LtuyraxrW5H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import FastText"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('review.csv')\n",
        "sentences = []\n",
        "\n",
        "for row in df.Review:\n",
        "    s = str(row)\n",
        "    lst = word_tokenize(s)\n",
        "    sentences.append(lst)\n",
        "print(len(sentences))"
      ],
      "metadata": {
        "id": "gMF3LWtHrnjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# min_count = 3 : words that appear fewer than 5 times will be dropped from the vocabulary and ignored during training.\n",
        "# workers is the number of threads for the training of the model, higher number = faster training.\n",
        "model = FastText(sentences, vector_size=100, window=5, min_count=3, workers=4, epochs=10, seed=42, sg=1)\n",
        "ftext = model.wv"
      ],
      "metadata": {
        "id": "hrRFvEyrrrML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ftext['good'])"
      ],
      "metadata": {
        "id": "yEQim4X8rrOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approach 2**: Without any fastText function. ⚡"
      ],
      "metadata": {
        "id": "3B0iV_j1szv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "zSd4vZv9tS2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/bbc-text.csv')"
      ],
      "metadata": {
        "id": "GEnaPgSXGX9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = df.apply(lambda row: f\"{row['text']}\\n\", axis=1).tolist()"
      ],
      "metadata": {
        "id": "CUq98aPCHgnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the text into character n-grams and whole words\n",
        "def extract_tokens(word, min_n=3, max_n=6):\n",
        "    ngrams = []\n",
        "    for n in range(min_n, max_n + 1):\n",
        "        ngrams += [word[i:i+n] for i in range(len(word) - n + 1)]\n",
        "    return [word] + ngrams"
      ],
      "metadata": {
        "id": "cF86MFiMtqSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "for sentence in corpus:\n",
        "    words = sentence.split()\n",
        "    ngram_sentence = [extract_tokens(word) for word in words]\n",
        "    sentences.append([token for tokens in ngram_sentence for token in tokens])"
      ],
      "metadata": {
        "id": "6xwFhx9ctuLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Word2Vec model on character n-grams and whole words\n",
        "model = Word2Vec(sentences, sg=1, vector_size=300, window=5, min_count=1, workers=4, epochs=50)"
      ],
      "metadata": {
        "id": "TnV95--6txuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to a file\n",
        "model.save(\"fasttext.model\")"
      ],
      "metadata": {
        "id": "JSI0BiMKt29B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from a file\n",
        "loaded_model = Word2Vec.load(\"fasttext.model\")"
      ],
      "metadata": {
        "id": "f0OdynC0t-Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access word vectors\n",
        "word_vectors = loaded_model.wv"
      ],
      "metadata": {
        "id": "zp9Ly708t-Ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_word = \"emotionally\"\n",
        "if input_word in word_vectors:\n",
        "    embedding_vector = word_vectors[input_word]\n",
        "    print(f\"Embedding vector for '{input_word}':\")\n",
        "    print(embedding_vector)\n",
        "else:\n",
        "    print(f\"'{input_word}' is not present in the vocabulary.\")"
      ],
      "metadata": {
        "id": "pN1UAqbfuFlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.similar_by_word('man')\n"
      ],
      "metadata": {
        "id": "Kv0iZKfTt-v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Gwhu1qiuIE1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}